Satya Nadella
Microsoft Corporation (MSFT) Q4 2023 Earnings Call Transcript

Thank you, Keith, for the question. The fundamental guidance and conversation that we have with customers is twofold. One is the easiest path to value out of generative AI is to adopt certain solutions, for example, GitHub Copilot. In some sense, it's sort of a no-brainer to add productivity leverage for all of the software developers in any organization. Whether you're a bank, you're a retailer or you're a software company, it applies to everyone. So that's probably one of the things that we have seen very good -- even productivity data and great adoption.

And then obviously, the excitement that there is already around the M365 Copilot. So first thing we sort of talk about is how we ourselves are deploying all these Copilots across, whether it's Sales Copilot or M365 Copilot or GitHub Copilot, how do you get maximum value out of these horizontal tool chain? And then on top of that, we have taken what we did underneath these products and built it out as a first-class tech stack, right, which we talked at our developer conference, called the Copilot Stack, and then with Azure AI tooling, made it possible for a someone like Moody's to build their own Copilot for their people.

So to us, we want to be able to help customers build their generative AI applications on top of Azure AI, and with speed, if you will. And so those are the 2 things that we ask them to identify where they can get the maximum productivity leverage. And then we even swung with our own resources to help them get those things done. And the last comment I'd make is the cloud and data in the cloud enables all this because I think the diffusion cycle here, in some sense, we have a new set of cloud meters that are getting adopted faster because of everything else that came before it in the cloud. So those would be the observations.

Sure, Brent. Thank you for the question. Yes, a couple of observations. One is, I think, overall in the cloud, you do see new project starts and then those project starts get optimized and then you sort of time-series all of that, and that's sort of what you see in the normal course. What happened here was during the pandemic, obviously, there were lots of new project starts and optimization in some sense was postponed, and that's where you're seeing, I'll call it, catch-up optimization. And that's something that, to your point, we will lap. Going into the next couple of quarters, I think, it will come down.

And we are seeing new project starts, both traditional type of project starts, even cloud migrations, data applications and, of course, obviously, the AI applications. But we'll get back to I'll call the normal pace of new project starts and optimizations going forward, that we will cycle through, I think, in the next couple of quarters, what is the last catch-up optimization.

Yes. And I think just for perspective, I think it's sort of always good to think about it, right, where we have, what, 111 [bill] (ph) commercial cloud business growing at, what, 22% year-over-year. And then you had a CapEx growth, which is around the same number, 23%, 24%. So in some sense, it's sort of replacement capital plus some new capital that is going to drive new growth. So that's, I think, the scale. And we feel good about that structure of overall growth rates and how it translates into future TAM opportunity for us.

And then to your other question on how all this translates into project starts effectively, the Copilot stack is available today on Azure. So we have everything from Azure AI tool chain where you can use obviously, Azure OpenAI or even you can use open models from Llama and Hugging Face models. You have all the Fabric and all of our operational data stores for what is one of the most useful patterns around generative AI as what is called Retrieval Augmented Generation, which is you take the data that you have in the data stores, use it in a prompt to generate completions, summaries, what have you. And so that's something that we've seen a lot of and the Copilots are fundamentally orchestrations of that. And so we have all of these services available.

The thing that's fascinating is when you use something like Power Virtual Agent, you have a low-code, no-code tool to build effectively these AI products or full-fledged Copilots like we've built. And all the underlying primitives for that are available on Azure. The tool chain is available on Azure and the speed with which customers are able to deploy them, ISVs are able to build them, is pretty impressive.

Sure. Kash, thanks for the question. So maybe I'll start and then, Amy, you can add because I think -- we do think about what's the long-term TAM here, right? I mean this is -- you've heard me talk about this as a percentage of GDP, what's going to be tech spend? If you believe that, let's say, the 5% of GDP is going to go to 10% of GDP, maybe that gets accelerated because of the AI wave. Then the question is how much of that goes to the various parts of our Commercial Cloud and then how competitive are we in each layer, right?

So if you sort of break it down, you sort of talked about how Microsoft 365, we think of this Copilot as a third pillar, right? We had the creation tools. We then had all the communication and collaboration services, and we think the AI Copilot is a third pillar. So we are excited about it. Amy talked about how we want to get it out first and part of this preview. And then in the second half of the next fiscal year, we'll start getting some of the real revenue signal from it. So we're looking forward to it.

But we think of it long term as a third pillar, like we thought about something like, say, Teams or SharePoint back in the day, or what have you. Then Azure, the way I think about it is we still are, whatever, you're inning 2 or inning 3 of even the cloud migration, especially if you view it, right, whether by industry moves to the cloud, segment move to the cloud as well as country adoption of the cloud, right? So there's still early innings of the cloud migration itself. So there's a lot there still.

And then on top of that, there's this complete new world of AI driving a set of new workloads. And so we think of that, again, being pretty expansive from a TAM opportunity and we'll play it out. But at the same time, we are a $111 billion commercial cloud that has grown in 20s, and so therefore, we do hit law of large numbers. But that said, we do think that this is a business that can have sustained high growth, which is something that we are excited about.

Yes. If I could just add to what Amy said, the platform effect here is really all about the extensibility of the Copilots. You see that today when people build applications in Teams that are built on Power Apps and those Power Apps happen to use something like SQL DB on Azure. That's like a classic line of business extension. So you'll see the same thing. When I have a Copilot plug-in, that plug-in uses Azure AI, Azure meters, Azure data sources, Azure semantic search. So you'll see, obviously, a pull through not only on the identity or security layer, but in the core PaaS services of Azure plus the Copilot extensibility in M365.

Yes. Judson Althoff would love you for having used his metaphor of remodeling every room of the house with AI because you're absolutely right. I mean that's the opportunity we see. I think what you're also referencing is now there's good empirical evidence and data around the GitHub Copilot and the productivity stats around it. And we're actively working on that for M365 Copilot, also for things like the role-based ones like Sales Copilot or Service Copilot. We see these business processes having very high productivity gains. And so yes, over the course of the year, we will have all of that evidence.

And I think at the end of the day, as Amy referenced, every CFO and CIO is also going to take a look at this. I do think for the first time -- or rather, I do think people are going to look at how can they complement their OpEx spend with essentially these Copilots in order to drive more efficiency and, quite frankly, even reduce the burden and drudgery of work on their OpEx and their people and so on. So therefore, I think you're going to see all of that translated into productivity stats, and we're looking forward to getting that data out.

Yes. I mean the thing that we are both seeing and excited about is both the new workloads. I mean if you think about Azure, we have grown Azure over the years coming from behind. And here we are as a strong #2 in the lead when it comes to these new workloads. So for example, we are seeing new logos, customers who may have used out of the cloud for most of what they do, or for the first time, sort of starting to use Azure for some of their new AI workloads.

We also have even customers who've used multiple clouds who use that for a class of sort of workloads also start new projects when it's transferred in data and AI, which they were using other clouds. So what I think you will see us is more share gains, more logo gains, reducing our CAC even. And so those are the things of points of leverage. But at the same time, we are not a small business anymore in any of these things. We're significantly -- we have significant scale. And so, yes, we celebrate. That's why we're even giving you the visibility at 1 point of it showing up this quarter, a couple of points showing up next quarter. And those are material numbers.

And so that's kind of what I think will track. And I think Amy mentioned it because we want -- there are 2 parts to even AI, right? There's the models themselves with our partnership with OpenAI. That's sort of one type of spend on compute. And the other is much more revenue-driven, right, which is we will track the inference cost to the revenue and demand. And you're already seeing both of those play out.

Yes, sure. Thank you for the question. Yes, absolutely. I think having your data, in particular, in the cloud is sort of key to how you can take advantage of essentially these new AI reasoning engines to complement, I'll call it, your databases because these AI engines are not databases, but they can reason over your data and to help you then get more insights, more completions, more predictions, more summaries, and what have you.

So those are the things when we say Copilot design pattern, that's sort of what that design pattern is all about. The thing that perhaps even in the last quarter, and I had that in my remarks, that's most exciting is how with Microsoft Fabric, especially for the analytics workloads, we brought together compute, storage, governance with a very disruptive business model.

I mean to give you a flavor for it, right, so you have your data in an Azure data lake. You can bring SQL Compute to it. You can bring Spark to it. You can bring Azure AI or Azure OpenAI to it, right? So the fact is you have storage separated from all these compute meters, and they're all interchangeable, right? So you don't have to buy each of these separately. That's the disruptive business model. So I feel that we are well -- Microsoft is very well positioned with the way our data architecture lays out our business model around data and how people will plan to use data with AI services. So that's kind of what I mean by getting your data estate in order. And it's just not getting data estate in order but you have to have it structured such that you can have the flexibility that allows you to exercise the data and compute in combinations that makes sense for this new age.

Thank you, all.

