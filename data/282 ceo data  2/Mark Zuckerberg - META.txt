Meta Platforms, Inc. (META) Q4 2023 Earnings Call Transcript

Mark Zuckerberg

I'll take the first one. So the themes for the year of efficiency were to make us a stronger technology company by becoming leaner and more balanced towards our engineering work and more streamlined and to improve our financial performance, primarily with the goal of providing stability, so we can invest in these long-term ambitious visions around AI and metaverse over what we see as the coming decade or more as these things play out.

And I think a lot of people looked at what we were doing as if it might have been some kind of short-term thing, which that's never really our focus. But the part about making the company leaner, I think, is the more important part to take forward, right? Because obviously, we're in a place now where the business is performing well. And I think the obvious question would be, okay, well, given that, should we just -- should we invest a lot more in things?

And the biggest thing that's holding me back from doing that is that at this point, I feel like I've really come around to thinking that we operate better as a leaner company. So even though it's always -- there's always questions about like adding a few people here or there to do something. And I guess I just have more of an appreciation about how all of that adds up and in the near-term, maybe makes you go a little bit faster. But over the long-term, the discipline to kind of hold things to a more streamlined level actually improves the overall company performance. So I'm really focused on that.

In 2024, we do have a big recruiting backlog from last year because part of the layoffs that we did included teams basically swapping out certain talent profiles for others. And we still need to hire some of the other talent profiles that we swapped people out for, and that will be ongoing through this year. But in terms of new head count that we added to the plan, it's relatively minimal compared to what we would have done historically.

And I sort of expect that for the next period of time going forward, even beyond 2024. My operating assumption is that we will also try to keep it relatively minimal because I think that -- until we reach a point where we're just really underwater on our ability to execute, I kind of want to keep things lean because I think that's the right thing for us to do culturally. So that's kind of the best window into how I'm thinking about this.

The other piece that, I guess, somewhat dovetails into what Susan is going to talk to you next is that a big part of why I wanted to improve our profitability is to give ourselves the ability to go through what is a somewhat unpredictable and volatile period over the next 5 or 10 years. There are different risk factors that are geopolitical or regulatory or different things, but also the technology landscape is somewhat unknown. And we want the ability to be able to surge investment on things like building out larger training clusters or just making different investments where that's necessary.

And in order to make sure that we have the flexibility to do that, we want to make sure that we keep our cost structure to a point where we sort of have some extra space built in. So those are really the 2 points. That was the theme that I laid out at the beginning of the year of efficiency last year: make us a stronger technology company and give us the flexibility and stability to execute the long-term goals. And those remain, I think, the big focuses going forward on that.

Sure. I can take the first one. I do think that AI is going to make all of the products and services that we use and make better. So it's hard to know exactly how that will play out. But for the work in Reality Labs, specifically, there's a bunch of areas. Like if you take smart glasses, before, we thought that we would have to build like full displays and holograms and deliver the sense of presence before that became a mainstream product.

And now it seems quite possible that smart glasses that have AI assistance built in will be the killer app, and that the holograms and sense of presence will come later as a -- maybe on the same time horizon we were talking about before but could end up being just as important as we expected. But there could be a big market here even before that. So I think we'll figure that out over the next few years. But yes, I mean, overall, I think the 2 go together pretty hand-in-hand. I would have predicted that a lot of the parts of Reality Labs -- I guess the sequence in technology is sometimes surprising.

We always kind of expected that as part of building glasses or any of these platforms that having an AI assistant would be a foundational part of it. But the fact that that's -- that there have just been big strides in that over the last year or 2 is just -- is a big opportunity for these products sooner. So I think it's still unknown exactly how that will play out, but I think we'll know more over the next few years. It's very exciting, though.

I can talk to the first one. Yes, the whole reason why we moved FAIR is basically to be closer to the GenAI group. They're both research groups. The GenAI group basically builds our Llama launch vehicles and products, but also conducts a fair amount of research, too, especially things that are going to be coming into the upcoming versions of Llama. FAIR is focused on more foundational work and longer-term work. So it's, I'd say, more things that might be a couple of years out to 10-plus years out. And as we -- I guess, here's one way to think about it.

A lot of last year and the work that we're doing with Llama 3 is basically making sure that we can scale our efforts to really produce state-of-the-art models. But once we get past that, there's a lot more kind of different research that I think we're going to be doing that's going to take our foundation models in potentially different directions than other players in the industry are going to go in because we're focused on specific vision for what we're building.

So it's really important as we think about what's going to be in Llama 5 or 6 or 7 and what cognitive abilities we want in there and what modalities we want to build into future multimodal versions of the models. We need to be doing that work in advance and to research those things. And it helps to -- and even though FAIR and GenAI will continue to be 2 kind of separate groups on different time horizons.

I think to have some level of alignment between -- on the vision of what we're building between the 2 of them, so that way, the FAIR team can have in mind, hey, if we research this, then maybe it can intercept Llama 6 or something. Then that, I think, is just going to be more helpful for increasing the ambition and focus of all of the work that we do.

It's one of the reasons that I talked about. We did open-ended research on AI for a while. But having a clear product target with these AI agents, I think, is really going to help focus the work and give us a feedback loop that's going to increase the productivity and output that we get dramatically.

I don't think that the Apple thing is going to have any difference for us because I think that the way that they've implemented it, I would be very surprised if any developer chose to go into the alternative App Stores that they have. They've made it so onerous, and I think so at odds with the intent of what the EU regulation was that I think it's just going to be very difficult for anyone, including ourselves, to really seriously entertain what they're doing there.

Susan, did you want to add anything?

Yes. I think having a good assistant is going to be one of the real values that this generation of AI creates as well as giving every creator an opportunity to have an assistant or agent that people can engage with and every business and agent and also allowing people to create a bunch of quirky and fun things as well. But yes, I think Meta AI is going to be very important across the product.

It currently is available in some countries in WhatsApp, Messenger and Instagram. It's at the phase where we're not really pushing it super proactively. We've sort of made it available, and as people use it, we're learning from how -- what are the basic ways that people want to engage with it. We're currently in the tuning phase on this. I mean, we started rolling this out, I think, it was in November or so, maybe October.

And I would expect that, over the course of this year, we are going to start rolling this out much more prominently across our apps. And that was sort of what I was saying in my opening remarks about the analogy to Stories, where we ran a bunch of experiments, put it out there, got feedback and then eventually did a lot of integrations, even to the point where people were making jokes about us putting Stories in settings, which, for the record, never happened, but I found funny.

So I think that we're going to be on that journey this year. We're basically in the learning and tuning phase now. I'm happy with how that's going. We're currently working on and planning the next set of integrations and places where this is going to be available to people across the products, and I'm really looking forward to that. And I think that's going to be one of the big themes for '24 for us.